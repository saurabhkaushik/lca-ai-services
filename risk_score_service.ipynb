{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/saurabhkaushik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/saurabhkaushik/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/saurabhkaushik/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/saurabhkaushik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/saurabhkaushik/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/saurabhkaushik/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')\n",
    "\n",
    "#!pip3 install negspacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-11-12 19:19:45.118350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence : Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.\n",
      "Original Score:  90\n",
      "-86.26590371131897 90\n",
      "Adjusted Score:  51.180343329906464\n",
      "Sentence : Nick has high warranty liability, but he has does not high wealth.\n",
      "Original Score:  90\n",
      "-99.78210926055908 90\n",
      "Adjusted Score:  45.09805083274841\n",
      "Sentence : Nick has low warranty liability\n",
      "Original Score:  90\n",
      "-99.69357252120972 90\n",
      "Adjusted Score:  45.13789236545563\n",
      "Sentence : Nick dont have warranty liability.\n",
      "Original Score:  90\n",
      "-84.78177189826965 90\n",
      "Adjusted Score:  51.848202645778656\n",
      "Sentence : Nick has warranty liability.\n",
      "Original Score:  90\n",
      "-99.81701374053955 90\n",
      "Adjusted Score:  45.0823438167572\n",
      "Sentence : She does not like Steve Jobs but likes Apple products.\n",
      "Original Score:  90\n",
      "98.87738227844238 90\n",
      "Adjusted Score:  134.49482202529907\n",
      "Sentence : He does not like Adolf Hitler but likes German products.\n",
      "Original Score:  90\n",
      "99.23375248908997 90\n",
      "Adjusted Score:  134.65518862009048\n",
      "Sentence : There is no English language option.\n",
      "Original Score:  90\n",
      "-99.95936751365662 90\n",
      "Adjusted Score:  45.01828461885452\n",
      "Sentence : I had very high shortterm loans.\n",
      "Original Score:  90\n",
      "-99.55904483795166 90\n",
      "Adjusted Score:  45.19842982292175\n"
     ]
    }
   ],
   "source": [
    "from app.Risk_Score_Service import Risk_Score_Service\n",
    "from negspacy.negation import Negex\n",
    "import spacy \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"negex\")\n",
    "\n",
    "text_list1 = ['Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.', \n",
    "    'Organsation has high warranty liability', 'Organsation has low warranty liability', 'Organsation dont have warranty liability', 'Organsation has warranty liability']\n",
    "\n",
    "text_list2 = ['Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.', \n",
    "    'Nick has high warranty liability, but he has does not high wealth.', 'Nick has low warranty liability', 'Nick dont have warranty liability.', 'Nick has warranty liability.','She does not like Steve Jobs but likes Apple products.',\n",
    "    'He does not like Adolf Hitler but likes German products.', 'There is no English language option.', 'I had very high shortterm loans.']\n",
    "\n",
    "risk_scorer = Risk_Score_Service()\n",
    "\n",
    "#text_list2 = ['I had very high current liability.', 'My current liability are low.']\n",
    "\n",
    "for sentence in text_list2:\n",
    "    score = 90\n",
    "    print('Sentence :', sentence)\n",
    "    print('Original Score: ', score)\n",
    "    adj_score = risk_scorer.calculate_score(sentence, score)\n",
    "    print('Adjusted Score: ', adj_score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e5532c3338948ef3923f84fcb49a3fec3185e68b18b7cb85088cd68c49cbe22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

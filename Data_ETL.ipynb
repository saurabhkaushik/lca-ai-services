{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_service.training():liabilities\n",
      "DB Pool Created.\n",
      "Query:  SELECT * from training_data where domain='liabilities';\n",
      "SELECT * from training_data where domain='liabilities';\n",
      "Query:  SELECT * from training_data where domain='liabilities';\n",
      "SELECT * from training_data where domain='liabilities';\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/Users/saurabhkaushik/Workspace/lca-ai-services/app/Transformer_Classifier.py\", line 81, in training\n",
      "    train_hg, valid_hg = self.prepare_train_dataset(domain)\n",
      "  File \"/Users/saurabhkaushik/Workspace/lca-ai-services/app/Transformer_Classifier.py\", line 68, in prepare_train_dataset\n",
      "    random_state=2022\n",
      "  File \"/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/sklearn/model_selection/_split.py\", line 2421, in train_test_split\n",
      "    n_samples, test_size, train_size, default_test_size=0.25\n",
      "  File \"/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/sklearn/model_selection/_split.py\", line 2101, in _validate_shuffle_split\n",
      "    \"aforementioned parameters.\".format(n_samples, test_size, train_size)\n",
      "ValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_service.process_contract_training_data_eval():liabilities\n",
      "Query:  SELECT * from training_data where domain='liabilities';\n",
      "SELECT * from training_data where domain='liabilities';\n",
      "0\n",
      "None\n",
      "-1 record(s) affected\n",
      "key_classifier.Keyword Classifier Accuracy: liabilities\n",
      "SELECT * from seed_data where domain='liabilities';\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Traceback (most recent call last):\n",
      "  File \"/Users/saurabhkaushik/Workspace/lca-ai-services/app/Keyword_Classifier.py\", line 66, in evaluate_model\n",
      "    predicted = self.text_clf.predict(self.trainDF['text'])\n",
      "  File \"/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/sklearn/pipeline.py\", line 469, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\", line 1661, in transform\n",
      "    X, accept_sparse=\"csr\", dtype=FLOAT_DTYPES, copy=copy, reset=False\n",
      "  File \"/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/sklearn/base.py\", line 566, in _validate_data\n",
      "    X = check_array(X, **check_params)\n",
      "  File \"/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 808, in check_array\n",
      "    % (n_samples, array.shape, ensure_min_samples, context)\n",
      "ValueError: Found array with 0 sample(s) (shape=(0, 223)) while a minimum of 1 is required.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: label, dtype: float64)\n",
      "class_service.Transformer Classifier Accuracy: liabilities\n",
      "Query:  SELECT * from training_data where domain='liabilities';\n",
      "SELECT * from training_data where domain='liabilities';\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from app.Transformer_Classifier import Transformer_Classifier \n",
    "from app.Data_Loader import Data_Loader\n",
    "from app.TextRank_Extractor import TextRank_Extractor\n",
    "from app.Keyword_Classifier import Keyword_Classifier\n",
    "from app.common.MySQLUtility import MySQLUtility\n",
    "import os \n",
    "\n",
    "domains = ['esg', 'liabilities' ] #'liabilities', 'esg'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = './store/genuine-wording-key.json'\n",
    "\n",
    "DB_HOST = '34.170.168.203'\n",
    "DB_USER = 'root'\n",
    "DB_PASSWORD = 'nu123456'\n",
    "DB_NAME = 'lca_db'\n",
    "\n",
    "class Data_ETL_Pipeline(object):\n",
    "    dbutil = None\n",
    "    data_load = None\n",
    "    textrank = None \n",
    "    key_classifier = None\n",
    "    class_service = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dbutil = MySQLUtility(DB_HOST, DB_USER, DB_PASSWORD, DB_NAME)\n",
    "        self.data_load = Data_Loader(self.dbutil)\n",
    "        self.textrank = TextRank_Extractor(self.dbutil)\n",
    "        self.key_classifier = Keyword_Classifier(self.dbutil)\n",
    "        self.class_service = Transformer_Classifier(self.dbutil)\n",
    "        pass    \n",
    "\n",
    "    def create_dataset(self):\n",
    "        print(\"dbutil.db_cleanup():\")\n",
    "        self.dbutil.clean_db()\n",
    "        print(\"dbutil.create_database():\")\n",
    "        self.dbutil.create_database() \n",
    "\n",
    "    def load_seed_training_data(self):\n",
    "        print(\"data_load.import_seed_data_batch():\")\n",
    "        self.data_load.import_seed_data_batch()\n",
    "\n",
    "        for domain in domains:\n",
    "            print(\"textrank.extract_keyword_seed_data():\" + domain)\n",
    "            self.textrank.extract_keyword_seed_data(domain) \n",
    "\n",
    "            print(\"textrank.load_seed_to_training_data_batch():\" + domain)\n",
    "            self.data_load.load_seed_to_training_data_batch(domain) \n",
    "    \n",
    "    def load_contract_data(self):\n",
    "        for domain in domains:\n",
    "            print(\"self.data_load.import_reports_contract_data()\" + domain)\n",
    "            self.data_load.import_reports_contract_data(domain)\n",
    "\n",
    "    def process_keyword_model(self):\n",
    "        for domain in domains:\n",
    "            print(\"key_classifier.prepare_training_data():\" + domain)\n",
    "            self.key_classifier.prepare_training_data(domain)\n",
    "\n",
    "            print(\"key_classifier.train_model():\" + domain)\n",
    "            self.key_classifier.train_model(domain)\n",
    "\n",
    "            print(\"key_classifier.evaluate_model():\" + domain)\n",
    "            self.key_classifier.evaluate_model(domain)\n",
    "\n",
    "            print(\"key_classifier.process_contract_data():\" + domain)\n",
    "            self.key_classifier.process_contract_data(domain)\n",
    "\n",
    "    def process_transformer_model(self):\n",
    "        for domain in domains:\n",
    "            print(\"class_service.training():\" + domain)\n",
    "            self.class_service.training(domain)    \n",
    "\n",
    "            print(\"class_service.process_contract_training_data_eval():\" + domain)\n",
    "            self.class_service.process_contract_training_data_eval(domain)\n",
    "\n",
    "    def evaluate_results(self):\n",
    "        for domain in domains:\n",
    "            print (\"key_classifier.Keyword Classifier Accuracy: \" + domain)\n",
    "            self.key_classifier.evaluate_model(domain) \n",
    "            \n",
    "            print (\"class_service.Transformer Classifier Accuracy: \" + domain)\n",
    "            self.class_service.evalute_model(domain)\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    dbloader = Data_ETL_Pipeline()\n",
    "    #dbloader.create_dataset()\n",
    "    #dbloader.load_seed_training_data() \n",
    "    #dbloader.load_contract_data()\n",
    "    #dbloader.process_keyword_model()\n",
    "    dbloader.process_transformer_model()\n",
    "    dbloader.evaluate_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading Models to GCP Bucket.\n",
      "File ./model/liabilities/config.json uploaded to liabilities/config.json.\n",
      "Uploaded liabilities/config.json.\n",
      "File ./model/liabilities/keyword_class.joblib uploaded to liabilities/keyword_class.joblib.\n",
      "Uploaded liabilities/keyword_class.joblib.\n",
      "File ./model/liabilities/pytorch_model.bin uploaded to liabilities/pytorch_model.bin.\n",
      "Uploaded liabilities/pytorch_model.bin.\n",
      "File ./model/esg/config.json uploaded to esg/config.json.\n",
      "Uploaded esg/config.json.\n",
      "File ./model/esg/keyword_class.joblib uploaded to esg/keyword_class.joblib.\n",
      "Uploaded esg/keyword_class.joblib.\n",
      "File ./model/esg/pytorch_model.bin uploaded to esg/pytorch_model.bin.\n",
      "Uploaded esg/pytorch_model.bin.\n"
     ]
    }
   ],
   "source": [
    "from app.common.GCP_Storage import GCP_Storage\n",
    "\n",
    "import os \n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = './store/genuine-wording-key.json'\n",
    "\n",
    "domains = ['liabilities', 'esg']\n",
    "loader = GCP_Storage(domains)\n",
    "\n",
    "#loader.setup_bucket()\n",
    "loader.upload_models()\n",
    "#loader.download_models()\n",
    "#loader.download_seed_data()\n",
    "#loader.upload_seed_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e5532c3338948ef3923f84fcb49a3fec3185e68b18b7cb85088cd68c49cbe22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install spacytextblob\n",
    "!python3 -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q transformers\n",
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.\", \"The company has recieved $417 million for the payment of interest. \"]\n",
    "text_list2 = ['Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.', \n",
    "    'Nick has high warranty liability, but he has does not high wealth.', 'Nick has low warranty liability', 'Nick dont have warranty liability.', 'Nick has warranty liability.','She does not like Steve Jobs but likes Apple products.',\n",
    "    'He does not like Adolf Hitler but likes German products.', 'There is no English language option.', 'I had very high shortterm loans.']\n",
    "for strr in text_list2:\n",
    "    data = [strr] \n",
    "    sentr = sentiment_pipeline(data)\n",
    "    print(sentr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "text = 'Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.'\n",
    "\n",
    "\n",
    "text_list2 = ['Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.', \n",
    "    'Nick has high warranty liability, but he has does not high wealth.', 'Nick has low warranty liability', 'Nick dont have warranty liability.', 'Nick has warranty liability.','She does not like Steve Jobs but likes Apple products.',\n",
    "    'He does not like Adolf Hitler but likes German products.', 'There is no English language option.', 'I had very low short term loans.']\n",
    "for strr in text_list2:\n",
    "    '''doc = nlp(strr)\n",
    "    sentiment_str1 = doc._.blob.polarity                            \n",
    "    print(sentiment_str1)'''\n",
    "    sia_r = sia.polarity_scores(strr)\n",
    "    print(sia_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U textblob\n",
    "!python3 -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''\n",
    "content = \"The company has $680 million for the payment of interest and penalties accrued at December.\"\n",
    "content = \"I am increasing my debt.\"\n",
    "\n",
    "\n",
    "blob = TextBlob(content)\n",
    "blob.tags           # [('The', 'DT'), ('titular', 'JJ'),\n",
    "                    #  ('threat', 'NN'), ('of', 'IN'), ...]\n",
    "\n",
    "blob.noun_phrases   # WordList(['titular threat', 'blob',\n",
    "                    #            'ultimate movie monster',\n",
    "                    #            'amoeba-like mass', ...])\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)\n",
    "# 0.060\n",
    "# -0.341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "text = 'I had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.'\n",
    "doc = nlp(text)\n",
    "\n",
    "polarity = doc._.blob.polarity                            # Polarity: -0.125\n",
    "doc._.blob.subjectivity                        # Subjectivity: 0.9\n",
    "doc._.blob.sentiment_assessments.assessments   # Assessments: [(['really', 'horrible'], -1.0, 1.0, None), (['worst', '!'], -1.0, 1.0, None), (['really', 'good'], 0.7, 0.6000000000000001, None), (['happy'], 0.8, 1.0, None)]\n",
    "doc._.blob.ngrams()                            # [WordList(['I', 'had', 'a']), WordList(['had', 'a', 'really']), WordList(['a', 'really', 'horrible']), WordList(['really', 'horrible', 'day']), WordList(['horrible', 'day', 'It']), WordList(['day', 'It', 'was']), WordList(['It', 'was', 'the']), WordList(['was', 'the', 'worst']), WordList(['the', 'worst', 'day']), WordList(['worst', 'day', 'ever']), WordList(['day', 'ever', 'But']), WordList(['ever', 'But', 'every']), WordList(['But', 'every', 'now']), WordList(['every', 'now', 'and']), WordList(['now', 'and', 'then']), WordList(['and', 'then', 'I']), WordList(['then', 'I', 'have']), WordList(['I', 'have', 'a']), WordList(['have', 'a', 'really']), WordList(['a', 'really', 'good']), WordList(['really', 'good', 'day']), WordList(['good', 'day', 'that']), WordList(['day', 'that', 'makes']), WordList(['that', 'makes', 'me']), WordList(['makes', 'me', 'happy'])]\n",
    "print ('Polarity:', polarity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Demonstrates how to make a simple call to the Natural Language API.\"\"\"\n",
    "import os\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = './store/genuine-wording-key.json'\n",
    "\n",
    "import argparse\n",
    "from google.cloud import language_v1\n",
    "\n",
    "def print_result(annotations):\n",
    "    score = annotations.document_sentiment.score\n",
    "    magnitude = annotations.document_sentiment.magnitude\n",
    "\n",
    "    for index, sentence in enumerate(annotations.sentences):\n",
    "        sentence_sentiment = sentence.sentiment.score\n",
    "        print(\n",
    "            \"Sentence {} has a sentiment score of {}\".format(index, sentence_sentiment)\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        \"Overall Sentiment: score of {} with magnitude of {}\".format(score, magnitude)\n",
    "    )\n",
    "    return 0\n",
    "\n",
    "def analyze(movie_review_filename):\n",
    "    \"\"\"Run a sentiment analysis request on text within a passed filename.\"\"\"\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    content = \"The company has $680 million for the payment of interest and penalties accrued at December.\"\n",
    "    #content = 'Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.'\n",
    "\n",
    "    document = language_v1.Document(\n",
    "        content=content, type_=language_v1.Document.Type.PLAIN_TEXT\n",
    "    )\n",
    "    annotations = client.analyze_sentiment(request={\"document\": document})\n",
    "\n",
    "    # Print the results\n",
    "    print_result(annotations)\n",
    "\n",
    "\n",
    "analyze(\"ddd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (v3.7.9:13c94747c7, Aug 15 2020, 01:31:08) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e5532c3338948ef3923f84fcb49a3fec3185e68b18b7cb85088cd68c49cbe22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

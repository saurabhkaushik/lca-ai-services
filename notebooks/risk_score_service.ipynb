{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')\n",
    "''' \n",
    "!pip3 install negspacy\n",
    "!pip3 install spacy\n",
    "!python3 -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs: ['had']\n",
      "Adverbs: ['high', 'current']\n",
      "had <-> positive -0.02179403913619879\n",
      "had <-> negative 0.0015566577079735616\n",
      "Negative Word : had\n",
      "high <-> positive 0.8001796091831105\n",
      "high <-> negative 0.8117073158341684\n",
      "Negative Word : high\n",
      "current <-> positive 0.75096086695597\n",
      "current <-> negative 0.742650220384534\n",
      "Negative Word : current\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "  \n",
    "text = (\"\"\"My name is Shaurya Uppal. \n",
    "I enjoy writing articles on GeeksforGeeks checkout\n",
    "my other article by going to my profile section.\"\"\")\n",
    "  \n",
    "text = (\"I had very high current liability.\")\n",
    "\n",
    "doc = nlp(text)\n",
    "print(\"Verbs:\", [token.text for token in doc if token.pos_ == \"VERB\"])\n",
    "print(\"Adverbs:\", [token.text for token in doc if token.pos_ == \"ADJ\"])\n",
    "\n",
    "for token in doc:\n",
    "  if token.pos_ == \"ADJ\" or token.pos_ == \"VERB\":\n",
    "    doc1 = nlp(token.text)\n",
    "    doc2 = nlp(\"positive\")\n",
    "    doc3 = nlp(\"negative\")\n",
    "    # Similarity of two documents\n",
    "    d_positive = doc1.similarity(doc2)\n",
    "    d_negative = doc1.similarity(doc2)\n",
    "    print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
    "    print(doc1, \"<->\", doc3, doc1.similarity(doc3))\n",
    "    if d_positive > d_negative: \n",
    "      print ('Positive Word :', token.text), \n",
    "    else: \n",
    "      print ('Negative Word :', token.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install negspacy\n",
    "#!pip3 install -U textblob\n",
    "#!python3 -m textblob.download_corpora\n",
    "\n",
    "from app.Risk_Score_Service import Risk_Score_Service\n",
    "import spacy \n",
    "from textblob import TextBlob\n",
    "from negspacy.negation import Negex\n",
    "  \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "#nlp.add_pipe(\"negex\")\n",
    "\n",
    "text_list1 = ['Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.', \n",
    "    'Organsation has high warranty liability', 'Organsation has low warranty liability', 'Organsation dont have warranty liability', 'Organsation has warranty liability']\n",
    "\n",
    "text_list2 = ['I had very high current liability.', 'My current liability are low.']\n",
    "\n",
    "text_list2 = ['Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.', \n",
    "    'Nick has high warranty liability, but he has does not high wealth.', 'Nick has low warranty liability', 'Nick dont have warranty liability.', 'Nick has warranty liability.','She does not like Steve Jobs but likes Apple products.',\n",
    "    'He does not like Adolf Hitler but likes German products.', 'There is no English language option.', 'I had very high shortterm loans.']\n",
    "text = 'I had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This loan debt is increasing my financial burden.\n",
      "Polarity:  0.0\n",
      "Subjectivity:  0.0\n",
      "Sentiments:  [(['financial'], 0.0, 0.0, None)]\n",
      "N Grams :  [WordList(['This', 'loan', 'debt']), WordList(['loan', 'debt', 'is']), WordList(['debt', 'is', 'increasing']), WordList(['is', 'increasing', 'my']), WordList(['increasing', 'my', 'financial']), WordList(['my', 'financial', 'burden'])]\n",
      "Polarity 2:  0.0\n",
      "This loan debt is decreasing my financial burden.\n",
      "Polarity:  0.0\n",
      "Subjectivity:  0.0\n",
      "Sentiments:  [(['financial'], 0.0, 0.0, None)]\n",
      "N Grams :  [WordList(['This', 'loan', 'debt']), WordList(['loan', 'debt', 'is']), WordList(['debt', 'is', 'decreasing']), WordList(['is', 'decreasing', 'my']), WordList(['decreasing', 'my', 'financial']), WordList(['my', 'financial', 'burden'])]\n",
      "Polarity 2:  0.0\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install spacytextblob\n",
    "\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "text = 'I had a really horrible day. It was the worst day ever! But every now and then I have a really good day that makes me happy.'\n",
    "text_list2 = ['This loan debt is increasing my financial burden.', 'This loan debt is decreasing my financial burden.']\n",
    "\n",
    "for text in text_list2:\n",
    "    doc = nlp(text)\n",
    "    print (text)\n",
    "    print('Polarity: ', doc._.blob.polarity)\n",
    "    print('Subjectivity: ', doc._.blob.subjectivity)\n",
    "    print('Sentiments: ', doc._.blob.sentiment_assessments.assessments)\n",
    "    print('N Grams : ', doc._.blob.ngrams() )\n",
    "    print('Polarity 2: ', doc._.polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good <-> negative 0.36868476702276626\n",
      "good <-> positive 0.4219575404565682\n"
     ]
    }
   ],
   "source": [
    "#!python3 -m spacy download en_core_web_md\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")  # make sure to use larger package!\n",
    "doc1 = nlp(\"good\")\n",
    "doc2 = nlp(\"negative\")\n",
    "doc3 = nlp(\"positive\")\n",
    "\n",
    "# Similarity of two documents\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
    "print(doc1, \"<->\", doc3, doc1.similarity(doc3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.\n",
      "current <-> positive 0.75096086695597\n",
      "current <-> negative 0.742650220384534\n",
      "current ADJ\n",
      "0.008310646571435987\n",
      "Negative Word : current\n",
      "Marketable <-> positive 0.6077205796390635\n",
      "Marketable <-> negative 0.5561428172971951\n",
      "Marketable ADJ\n",
      "0.051577762341868394\n",
      "Positive Word : Marketable\n",
      "current <-> positive 0.75096086695597\n",
      "current <-> negative 0.742650220384534\n",
      "current ADJ\n",
      "0.008310646571435987\n",
      "Negative Word : current\n",
      "Nick has high warranty liability, but he has does not high wealth.\n",
      "high <-> positive 0.8001796091831105\n",
      "high <-> negative 0.8117073158341684\n",
      "high ADJ\n",
      "0.011527706651057956\n",
      "Positive Word : high\n",
      "high <-> positive 0.8001796091831105\n",
      "high <-> negative 0.8117073158341684\n",
      "high ADJ\n",
      "0.011527706651057956\n",
      "Positive Word : high\n",
      "Nick has low warranty liability\n",
      "low <-> positive 0.7578545238706568\n",
      "low <-> negative 0.8233932909516087\n",
      "low ADJ\n",
      "0.06553876708095197\n",
      "Positive Word : low\n",
      "Nick dont have warranty liability.\n",
      "Nick has warranty liability.\n",
      "She does not like Steve Jobs but likes Apple products.\n",
      "like <-> positive 0.2184902250886891\n",
      "like <-> negative 0.24124275088674352\n",
      "like VERB\n",
      "0.022752525798054424\n",
      "Positive Word : like\n",
      "likes <-> positive 0.09500934386963913\n",
      "likes <-> negative 0.18645251243170408\n",
      "likes VERB\n",
      "0.09144316856206494\n",
      "Positive Word : likes\n",
      "He does not like Adolf Hitler but likes German products.\n",
      "like <-> positive 0.2184902250886891\n",
      "like <-> negative 0.24124275088674352\n",
      "like VERB\n",
      "0.022752525798054424\n",
      "Positive Word : like\n",
      "likes <-> positive 0.09500934386963913\n",
      "likes <-> negative 0.18645251243170408\n",
      "likes VERB\n",
      "0.09144316856206494\n",
      "Positive Word : likes\n",
      "German <-> positive 0.5808113960771992\n",
      "German <-> negative 0.5022536984400869\n",
      "German ADJ\n",
      "0.07855769763711229\n",
      "Positive Word : German\n",
      "There is no English language option.\n",
      "English <-> positive 0.6064253473223014\n",
      "English <-> negative 0.6280974116587875\n",
      "English ADJ\n",
      "0.021672064336486163\n",
      "Positive Word : English\n",
      "I had very high shortterm loans.\n",
      "high <-> positive 0.8001796091831105\n",
      "high <-> negative 0.8117073158341684\n",
      "high ADJ\n",
      "0.011527706651057956\n",
      "Positive Word : high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "/Users/saurabhkaushik/Workspace/lca-ai-services/env/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "  \n",
    "text_list1 = ['Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.', \n",
    "    'Organsation has high warranty liability', 'Organsation has low warranty liability', 'Organsation dont have warranty liability', 'Organsation has warranty liability']\n",
    "\n",
    "text_list2 = ['I had very high current liability.', 'My current liability are low.']\n",
    "\n",
    "text_list2 = ['Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.', \n",
    "    'Nick has high warranty liability, but he has does not high wealth.', 'Nick has low warranty liability', 'Nick dont have warranty liability.', 'Nick has warranty liability.','She does not like Steve Jobs but likes Apple products.',\n",
    "    'He does not like Adolf Hitler but likes German products.', 'There is no English language option.', 'I had very high shortterm loans.']\n",
    "\n",
    "for text in text_list2:\n",
    "    doc = nlp(text)\n",
    "    print (text)\n",
    "    for token in doc:\n",
    "      if token.pos_ == \"ADJ\" or token.pos_ == \"VERB\":\n",
    "        if not token.is_stop:\n",
    "          doc1 = nlp(token.text)\n",
    "          doc2 = nlp(\"positive\")\n",
    "          doc3 = nlp(\"negative\")\n",
    "          # Similarity of two documents\n",
    "          d_positive = doc1.similarity(doc2)\n",
    "          d_negative = doc1.similarity(doc3)\n",
    "          print(doc1, \"<->\", doc2, d_positive)\n",
    "          print(doc1, \"<->\", doc3, d_negative)\n",
    "          print (token.text, token.pos_)\n",
    "          diff_d = abs(d_positive - d_negative)\n",
    "          print (diff_d)\n",
    "          if diff_d > 0.01: \n",
    "            print ('Positive Word :', token.text), \n",
    "          else: \n",
    "            print ('Negative Word :', token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marketable False -1\n",
      "$378 million False -1\n",
      "Prepaid False -1\n",
      "S Score : Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets. -100.0\n",
      "IBM False 3\n",
      "S Score : IBM has low warranty liability, but carried high wealth. 100.0\n",
      "Nick False 1\n",
      "S Score : Nick has low warranty liability 100.0\n",
      "Nick False 0\n",
      "S Score : Nick dont have warranty liability. 100.0\n",
      "Nick False 0\n",
      "S Score : Nick has warranty liability. 100.0\n",
      "Steve Jobs True 2\n",
      "Apple False 2\n",
      "S Score : She does not like Steve Jobs but likes Apple products. 100.0\n",
      "Hitler True 3\n",
      "German False 3\n",
      "S Score : He does not like Adolf Hitler but likes German products. 100.0\n",
      "English False 1\n",
      "S Score : There is no English language option. 100.0\n",
      "S Score : I had very high shortterm loans. 100.0\n"
     ]
    }
   ],
   "source": [
    "from app.Risk_Score_Service import Risk_Score_Service\n",
    "\n",
    "risk_service = Risk_Score_Service()\n",
    "\n",
    "text_list2 = ['Cash and cash equivalents and current Marketable securities, and $378 million in Prepaid expenses and other current assets.', \n",
    "    'IBM has low warranty liability, but carried high wealth.', 'Nick has low warranty liability', 'Nick dont have warranty liability.', 'Nick has warranty liability.','She does not like Steve Jobs but likes Apple products.',\n",
    "    'He does not like Adolf Hitler but likes German products.', 'There is no English language option.', 'I had very high shortterm loans.']\n",
    "\n",
    "for text in text_list2:\n",
    "    s_score = risk_service.get_semantic_score(text)\n",
    "    print ('S Score :', text, s_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Notes and other accounts receivable and other investments are financial assets with carrying values that approximate fair value',\n",
       " ' Accounts payable, other accrued expenses and short-term debt (excluding the current portion of long-term debt and including short- term finance lease liabilities) are financial liabilities with carrying values that approximate fair value',\n",
       " ' If measured at fair value in the financial statements, these financial instruments would be classified as Level 3 in the fair value hierarchy, except for short-term debt which would be classified as Level 2',\n",
       " ' Fair values are based on discounted future cash flows using current interest rates offered for similar loans to clients with similar credit ratings for the same remaining maturities',\n",
       " ' At December 31, 2021 and 2020, the difference between the carrying amount and estimated fair value for loans and long-term receivables was immaterial',\n",
       " ' If measured at fair value in the financial statements, these financial instruments would be classified as Level 3 in the fair value hierarchy',\n",
       " '']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Notes and other accounts receivable and other investments are financial assets with carrying values that approximate fair value. Accounts payable, other accrued expenses and short-term debt (excluding the current portion of long-term debt and including short- term finance lease liabilities) are financial liabilities with carrying values that approximate fair value. If measured at fair value in the financial statements, these financial instruments would be classified as Level 3 in the fair value hierarchy, except for short-term debt which would be classified as Level 2. \" + \\\n",
    "    \"Fair values are based on discounted future cash flows using current interest rates offered for similar loans to clients with similar credit ratings for the same remaining maturities. At December 31, 2021 and 2020, the difference between the carrying amount and estimated fair value for loans and long-term receivables was immaterial. If measured at fair value in the financial statements, these financial instruments would be classified as Level 3 in the fair value hierarchy.\"\n",
    "def sentences(text):\n",
    "    # split sentences and questions\n",
    "    text = re.split('[.?]', text)\n",
    "    clean_sent = []\n",
    "    for sent in text:\n",
    "        clean_sent.append(sent)\n",
    "        print (sent)\n",
    "    return clean_sent\n",
    "\n",
    "sentences(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e5532c3338948ef3923f84fcb49a3fec3185e68b18b7cb85088cd68c49cbe22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
